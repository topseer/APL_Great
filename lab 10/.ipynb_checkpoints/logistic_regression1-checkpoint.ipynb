{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import models\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic( z):\n",
    "    return 1.0 / (1.0 + np.exp( -z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(83474722)\n",
    "data = {}\n",
    "data[\"x1\"] = stats.norm.rvs(50.0, 5.0, 1000)\n",
    "p = 0.67\n",
    "data[\"x2\"] = np.array([1.0 if np.random.rand() < p else 0.0 for _ in range( 1000)])\n",
    "data[\"z\"] = data[\"x1\"] + 0.1*data[\"x2\"] + 0.25*data[\"x1\"]* data[\"x2\"] -50\n",
    "data[\"pr\"] = list(map(lambda z: logistic(z), data[\"z\"]))\n",
    "data[\"y\"] = list(map(lambda pr: 1 if np.random.uniform() < pr else 0, data[\"pr\"]))\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I set beta_0 to be a positive number but I kept getting the error \"This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1.0\". It turned out that when z is over a certain value (greater than 5 or less that -5) the logistic function is always very close to 1 and the logistic_regression would think the data it's getting only contains 1 class. So I set beta_0 to be -50 so that $z$ would be in a range that logistic($z$) would result in various values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 + x1:x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> -8.251427726352672 </td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 0.16762659722639675 </td></tr><tr><td>  x2  ($\\beta_2$) </td><td> -2.252408145921349 </td></tr><tr><td>  x1:x2 ($\\beta_3$) </td><td> 0.13537017628300727 </td></tr>\n",
       "    <tr><th colspan=2>metrics</th></tr>\n",
       "    <tr><td> Error (%) </td><td> 5.2 </td></tr>\n",
       "    <tr><td> $R^2$ </td><td> 0.6084918610068639 </td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = models.logistic_regression(\"y ~ x1 + x2 + x1:x2\", data = data)\n",
    "models.simple_describe_lgr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 + x1:x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th><th>95% BCI</th><th>P(y=1)</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> -8.251 </td><td>(-8.841, -7.569)</td><td>0.000</td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 0.168 </td><td>(0.153, 0.180)</td><td>0.042</td></tr><tr><td>  x2  ($\\beta_2$) </td><td> -2.252 </td><td>(-2.884, -1.428)</td><td>-0.563</td></tr><tr><td>  x1:x2 ($\\beta_3$) </td><td> 0.135 </td><td>(0.125, 0.146)</td><td>0.034</td></tr><tr><th colspan=2>metrics</th><th>95% BCI</th></tr><tr><td> Error (%) </td><td> 5.200 </td><td>(3.990, 6.810) </td></tr><tr><th> $R^2$ </th><td> 0.608 </td><td>(0.564, 0.642)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = models.bootstrap_logistic_regression(\"y ~ x1 + x2 + x1:x2\", data)\n",
    "models.describe_bootstrap_lgr(result, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the error rate and $R^2$ are not bad, the coefficients are quite different from the grounth truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
